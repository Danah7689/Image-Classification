{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsWYjEhYm6hi"
   },
   "source": [
    "#DNN Teq\n",
    "1. Load and Prepare MNIST Data:\n",
    "\n",
    "   - Download the MNIST dataset.\n",
    "   - Reshape the images to a flat format.\n",
    "   - Normalize the pixel values to be between 0 and 1.\n",
    "\n",
    "2. Convert Labels to One-Hot Encoding:\n",
    "\n",
    "   - Change the labels from numbers to a one-hot encoded format.\n",
    "\n",
    "3. Build the Neural Network (DNN):\n",
    "\n",
    "   - Create a sequential model.\n",
    "   - Add layers to the model, including dense layers and dropout layers.\n",
    "\n",
    "4. Train and Compile the Model Using Training Data:\n",
    "\n",
    "   - Compile the model with a loss function and optimizer.\n",
    "   - Train the model on the training data.\n",
    "\n",
    "5. Evaluate the Model Using Test Data:\n",
    "\n",
    "   - Test the model on unseen data to see how well it performs.\n",
    "\n",
    "6. Make Predictions Using the Test Data:\n",
    "\n",
    "   - Use the model to predict classes for the test images.\n",
    "   - Compare predicted classes with true labels.\n",
    "\n",
    "7. Input a New Image for Prediction:\n",
    "\n",
    "   - Load a new image.\n",
    "   - Preprocess the image and use the model to predict its class.\n",
    "   - Display the predicted class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dsZhUapRWGgP"
   },
   "outputs": [],
   "source": [
    "import numpy as np  # numpy: A library used for mathematical operations.\n",
    "\n",
    "import matplotlib.pyplot as plt  # matplotlib.pyplot: A library for displaying graphs and images.\n",
    "\n",
    "from keras.datasets import mnist  # keras.datasets: Contains ready-to-use datasets like MNIST, which has images of digits.\n",
    "\n",
    "from keras.models import Sequential  # keras.models: Used to create the neural network model that will learn from the data.\n",
    "\n",
    "from keras.layers import Dense, Dropout  # keras.layers: Used to create the layers inside the neural network.\n",
    "\n",
    "from keras.utils import to_categorical  # keras.utils: Contains helper functions, like converting numbers to certain formats.\n",
    "\n",
    "from keras.preprocessing import image  # Importing a library to load images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PtzgL9AXWdIW",
    "outputId": "48bd4b16-871b-455a-efa8-0592c3b4f8b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "#1-Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape the data to fit the DNN model\n",
    "x_train = x_train.reshape((x_train.shape[0], 28 * 28))  # Convert images to a flat shape (1D array).\n",
    "x_test = x_test.reshape((x_test.shape[0], 28 * 28))  # Standard size of 28 × 28 for MNIST images.\n",
    "\n",
    "# Normalize the data\n",
    "x_train = x_train.astype('float32') / 255.0  # Scale pixel values to be between 0 and 1.\n",
    "x_test = x_test.astype('float32') / 255.0  # Same normalization for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kSMyUA1sodz8"
   },
   "outputs": [],
   "source": [
    "# 2-Convert labels to a format suitable for use\n",
    "# Change labels from numbers to one-hot encoded format\n",
    "y_train = to_categorical(y_train, 10)  # Convert numbers to one-hot encoding (e.g., 0 → [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]).\n",
    "y_test = to_categorical(y_test, 10)  # Same for test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xiin17XLYQtc",
    "outputId": "76005a64-fc15-4106-8b98-c213fde927b6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#3-Build the Neural Network (DNN)\n",
    "model = Sequential()  # Create a sequential model.\n",
    "\n",
    "# First layer\n",
    "# Adding a \"Dense\" layer with 512 neurons. These neurons will learn patterns from the images.\n",
    "# `input_shape=(28 * 28,)` means the input will be a flat array of 784 numbers (28 * 28).\n",
    "model.add(Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "\n",
    "# Add a Dropout layer to reduce overfitting\n",
    "# This layer helps prevent the model from learning too much from the training data and becoming unable to generalize to new data.\n",
    "model.add(Dropout(0.2))  # 20% of neurons will be dropped during training.\n",
    "\n",
    "# Second layer\n",
    "# Another Dense layer with 512 neurons, where the model will learn more patterns from the data.\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Another Dropout layer\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Final layer\n",
    "# This is the last layer that will output the results. We have 10 neurons for the 10 digits (0 to 9).\n",
    "# The `softmax` function makes the sum of the values in this layer equal to 1, helping us determine the predicted digit.\n",
    "model.add(Dense(10, activation='softmax'))  # 10 outputs for the digits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "e1E5inRiYYXD",
    "outputId": "d65a5b63-1792-4163-ba66-b137d51d0548"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - accuracy: 0.8735 - loss: 0.4046 - val_accuracy: 0.9678 - val_loss: 0.1049\n",
      "Epoch 2/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - accuracy: 0.9691 - loss: 0.0996 - val_accuracy: 0.9716 - val_loss: 0.0926\n",
      "Epoch 3/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - accuracy: 0.9761 - loss: 0.0734 - val_accuracy: 0.9779 - val_loss: 0.0681\n",
      "Epoch 4/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - accuracy: 0.9827 - loss: 0.0538 - val_accuracy: 0.9794 - val_loss: 0.0699\n",
      "Epoch 5/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.9837 - loss: 0.0494 - val_accuracy: 0.9808 - val_loss: 0.0611\n",
      "Epoch 6/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.9870 - loss: 0.0403 - val_accuracy: 0.9776 - val_loss: 0.0773\n",
      "Epoch 7/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.9891 - loss: 0.0330 - val_accuracy: 0.9818 - val_loss: 0.0667\n",
      "Epoch 8/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - accuracy: 0.9889 - loss: 0.0318 - val_accuracy: 0.9821 - val_loss: 0.0650\n",
      "Epoch 9/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - accuracy: 0.9893 - loss: 0.0293 - val_accuracy: 0.9808 - val_loss: 0.0723\n",
      "Epoch 10/10\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - accuracy: 0.9917 - loss: 0.0256 - val_accuracy: 0.9805 - val_loss: 0.0740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x787fbeb1a200>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4-Compile and Train the Model\n",
    "\n",
    "# Compile the model\n",
    "# This line prepares the model and defines how it will be optimized during training.\n",
    "# \"categorical_crossentropy\" is the loss function used for multi-class classification.\n",
    "# \"adam\" is the optimizer that will be used to improve the model's performance.\n",
    "# \"accuracy\" is the metric that will be monitored to see how accurate the model is.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "# Here we train the model using the training data.\n",
    "# \"batch_size=64\" means 64 images will be trained at a time.\n",
    "# \"epochs=10\" means training will run for 10 complete passes over the data.\n",
    "# \"validation_data=(x_test, y_test)\" are the test data that help us see how well the model is classifying.\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehZ52rXCYf1R"
   },
   "outputs": [],
   "source": [
    "#5- Evaluate the Model Using Test Data\n",
    "\n",
    "# Evaluate the model using test data.\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)  # Get the accuracy and loss on the test data.\n",
    "print(f'Accuracy: {scores[1] * 100:.2f}%')  # Print the accuracy as a percentage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gg4NhslTr8Db"
   },
   "outputs": [],
   "source": [
    "#6- Make Predictions Using the Test Data\n",
    "\n",
    "# Make predictions using the test data\n",
    "predictions = model.predict(x_test)  # The model generates predictions for all images in the test set (x_test).\n",
    "\n",
    "# Convert predictions from probabilities to actual classes by taking the highest probability\n",
    "predicted_classes = np.argmax(predictions, axis=1)  # np.argmax selects the highest value in each prediction (represents the predicted class).\n",
    "\n",
    "# Convert true labels (which were in one-hot format) to actual numbers\n",
    "true_classes = np.argmax(y_test, axis=1)  # Convert true labels from one-hot format to actual numbers (0, 1, 2, ..., 9).\n",
    "\n",
    "# Display some images with predictions\n",
    "for i in range(10):  # Show 10 images from the test data.\n",
    "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')  # Display the image in the correct format (28x28) using grayscale.\n",
    "    plt.title(f'True: {true_classes[i]}, Predicted: {predicted_classes[i]}')  # Show the title with the true and predicted number.\n",
    "    plt.axis('off')  # Turn off the axes for a clearer image.\n",
    "    plt.show()  # Show the image with the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L0VJVN9yYn6Z"
   },
   "outputs": [],
   "source": [
    "#7-Input a New Image for Prediction\n",
    "\n",
    "# 1. Load a new image from the path (replace with the actual image path)\n",
    "img_path = '/content/drive/MyDrive/MNIST-2.webp'  # Specify the actual path of the image you want to input.\n",
    "img = image.load_img(img_path, target_size=(28, 28), color_mode='grayscale')  # Load the image and resize it.\n",
    "\n",
    "# 2. Convert the image to an array of pixels\n",
    "img_array = image.img_to_array(img)  # Convert the image to a numpy array.\n",
    "\n",
    "# 3. Normalize the image the same way MNIST data was normalized\n",
    "img_array = img_array.astype('float32') / 255.0  # Scale pixel values to be between 0 and 1.\n",
    "\n",
    "# 4. Reshape the image to fit the expected input of the neural network (28x28)\n",
    "img_array = img_array.reshape(1, 28 * 28)  # Convert the image to the appropriate shape (28*28).\n",
    "\n",
    "# 5. Make a prediction using the trained model\n",
    "prediction = model.predict(img_array)  # Predict the class for the new image.\n",
    "\n",
    "# 6. Display the prediction (the expected class)\n",
    "predicted_class = np.argmax(prediction, axis=1)  # Get the predicted class.\n",
    "print(f'Predicted Class for the input image: {predicted_class[0]}')  # Print the predicted class.\n",
    "\n",
    "# Show the input image with the prediction\n",
    "plt.imshow(img_array.reshape(28, 28), cmap='gray')  # Display the input image.\n",
    "plt.title(f'Predicted Class: {predicted_class[0]}')  # Show the predicted class in the title.\n",
    "plt.axis('off')  # Turn off the axes.\n",
    "plt.show()  # Show the image with the prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzqdFKMn0eFp"
   },
   "source": [
    "#CNN Teq\n",
    "#Steps:\n",
    "\n",
    "#1-Load the MNIST Dataset: Load the images and labels.\n",
    "\n",
    "#2-Reshape the Data: Change the shape of the data to fit the neural network model.\n",
    "\n",
    "#3-Normalize the Data: Scale the pixel values to the range [0, 1].\n",
    "\n",
    "#4-Convert Labels: Transform the labels into a suitable format for the model.\n",
    "\n",
    "#5-Build the CNN Model: Create the convolutional neural network model.\n",
    "\n",
    "#6-Compile the Model: Define the loss function, optimizer, and metrics.\n",
    "\n",
    "#7-Train the Model: Train the model on the training data.\n",
    "\n",
    "#8-Evaluate the Model: Assess the model's performance on the test data.\n",
    "\n",
    "#9-Display Some Results: Show some images with true labels and model predictions.\n",
    "\n",
    "#10-Input a New Image for Prediction: Load a new image, convert it, and predict the number contained in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "OYRASqR4bNVQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\danah\\AppData\\Local\\Temp\\ipykernel_28092\\1408224407.py\", line 5, in <module>\n",
      "    import matplotlib.pyplot as plt # matplotlib.pyplot: A library for displaying graphs and images.\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py\", line 129, in <module>\n",
      "    from . import _api, _version, cbook, _docstring, rcsetup\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\site-packages\\matplotlib\\rcsetup.py\", line 27, in <module>\n",
      "    from matplotlib.colors import Colormap, is_color_like\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\site-packages\\matplotlib\\colors.py\", line 56, in <module>\n",
      "    from matplotlib import _api, _cm, cbook, scale\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\site-packages\\matplotlib\\scale.py\", line 22, in <module>\n",
      "    from matplotlib.ticker import (\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\site-packages\\matplotlib\\ticker.py\", line 138, in <module>\n",
      "    from matplotlib import transforms as mtransforms\n",
      "  File \"C:\\Users\\danah\\anaconda3\\Lib\\site-packages\\matplotlib\\transforms.py\", line 49, in <module>\n",
      "    from matplotlib._path import (\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#1. Download the MNIST data set (so it is divided into test and training data)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#The model predicts the numbers in the images that have been inserted and downloaded\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \u001b[38;5;66;03m# numpy: A library used for mathematical operations.\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m \u001b[38;5;66;03m# matplotlib.pyplot: A library for displaying graphs and images.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mnist \u001b[38;5;66;03m# keras.datasets: Contains ready-to-use datasets like MNIST, which has images of digits.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Load the MNIST dataset\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\__init__.py:129\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse \u001b[38;5;28;01mas\u001b[39;00m parse_version\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# cbook must import matplotlib only within function\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# definitions, so it is safe to import from it here.\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _version, cbook, _docstring, rcsetup\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_sequence\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatplotlibDeprecationWarning\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\rcsetup.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcbook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ls_mapper\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Colormap, is_color_like\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_fontconfig_pattern\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_fontconfig_pattern\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\colors.py:56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _cm, cbook, scale\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_color_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BASE_COLORS, TABLEAU_COLORS, CSS4_COLORS, XKCD_COLORS\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_ColorMapping\u001b[39;00m(\u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\scale.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, _docstring\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     23\u001b[0m     NullFormatter, ScalarFormatter, LogFormatterSciNotation, LogitFormatter,\n\u001b[0;32m     24\u001b[0m     NullLocator, LogLocator, AutoLocator, AutoMinorLocator,\n\u001b[0;32m     25\u001b[0m     SymmetricalLogLocator, AsinhLocator, LogitLocator)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transform, IdentityTransform\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mScaleBase\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\ticker.py:138\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[1;32m--> 138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms \u001b[38;5;28;01mas\u001b[39;00m mtransforms\n\u001b[0;32m    140\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m    142\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTickHelper\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFixedFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    143\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNullFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFuncFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFormatStrFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    144\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStrMethodFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScalarFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogFormatter\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMultipleLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaxNLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAutoMinorLocator\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    151\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymmetricalLogLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsinhLocator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLogitLocator\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\matplotlib\\transforms.py:49\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inv\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     affine_transform, count_bboxes_overlapping_bbox, update_path_extents)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     53\u001b[0m DEBUG \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "#1. Download the MNIST data set (so it is divided into test and training data)\n",
    "#The model predicts the numbers in the images that have been inserted and downloaded\n",
    "\n",
    "import numpy as np # numpy: A library used for mathematical operations.\n",
    "import matplotlib.pyplot as plt # matplotlib.pyplot: A library for displaying graphs and images.\n",
    "from keras.datasets import mnist # keras.datasets: Contains ready-to-use datasets like MNIST, which has images of digits.\n",
    "\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DpWk_zVmbNVR"
   },
   "outputs": [],
   "source": [
    "#2. Data restructuring (We do this to make the images clear for the computer to handle them correctly)\n",
    "\n",
    "# Reshape the data to fit the CNN model\n",
    "x_train = x_train.reshape((x_train.shape[0], 28, 28, 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zO82zA9CbNVR"
   },
   "outputs": [],
   "source": [
    "#3. Data normalization (Converting pixels, which are colors, into smaller values so that they are easier to deal with)\n",
    "\n",
    "# Normalize the data\n",
    "x_train = x_train.astype('float32') / 255.0 # Scale pixel values to be between 0 and 1.\n",
    "x_test = x_test.astype('float32') / 255.0 # Same normalization for test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2K_AKRbUbNVR"
   },
   "outputs": [],
   "source": [
    "#4. Converting labels (Putting a special label on each image using One-Hot Encoding)\n",
    "\n",
    "from keras.utils import to_categorical  # keras.utils: Contains helper functions, like converting numbers to certain formats.\n",
    "\n",
    "# Convert labels to a suitable format\n",
    "y_train = to_categorical(y_train, 10) # Convert numbers to one-hot encoding (e.g., 0 → [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]).\n",
    "y_test = to_categorical(y_test, 10)# Same for test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRX3Zu8pbNVS"
   },
   "outputs": [],
   "source": [
    "#5. Building a CNN model (a new, empty model is built and then layers are added inside it, where each layer performs a specific task)\n",
    "\n",
    "from keras.models import Sequential # keras.models: Used to create the neural network model that will learn from the data.\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout  # keras.layers: Used to create the layers inside the neural network.\n",
    "\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolutional layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the data\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))  # Dropout layer to reduce overfitting\n",
    "model.add(Dense(10, activation='softmax'))  # Output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fap2UadZbNVS"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#6.Model assembly (Here we measure the extent of the error in the model prediction, the improvement of the model, the success of the model prediction)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# \"adam\" is the optimizer that will be used to improve the model's performance.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# \"accuracy\" is the metric that will be monitored to see how accurate the model is.\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#6.Model assembly (Here we measure the extent of the error in the model prediction, the improvement of the model, the success of the model prediction)\n",
    "\n",
    "# Compile the model\n",
    "# This line prepares the model and defines how it will be optimized during training.\n",
    "# \"categorical_crossentropy\" is the loss function used for multi-class classification.\n",
    "# \"adam\" is the optimizer that will be used to improve the model's performance.\n",
    "# \"accuracy\" is the metric that will be monitored to see how accurate the model is.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "etizrCDabNVS",
    "outputId": "8ba1100b-5ca6-4cb8-c54f-830aff936cd3"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#7.Training the model (Here we begin the training process)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# \"epochs=10\" means training will run for 10 complete passes over the data.\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# \"validation_data=(x_test, y_test)\" are the test data that help us see how well the model is classifying.\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x_train, y_train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(x_test, y_test))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#7.Training the model (Here we begin the training process)\n",
    "\n",
    "# Train the model\n",
    "# Here we train the model using the training data.\n",
    "# \"batch_size=64\" means 64 images will be trained at a time.\n",
    "# \"epochs=10\" means training will run for 10 complete passes over the data.\n",
    "# \"validation_data=(x_test, y_test)\" are the test data that help us see how well the model is classifying.\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SzJKt6thbNVS"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#8.Model Evaluation (The quality of the model being trained is measured)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m scores \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(x_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#8.Model Evaluation (The quality of the model being trained is measured)\n",
    "\n",
    "# Evaluate the model\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'Accuracy: {scores[1] * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "NPvqoaPWbNVS",
    "outputId": "e3dbc4a1-6256-48f0-f679-50bddc612377"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#9.Showing some results (The results are predicted according to the number in the pictures based on the test, determining which results obtained a higher value, displaying the results)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Display some results using test data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Make predictions using the test data\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(x_test) \u001b[38;5;66;03m# The model generates predictions for all images in the test set (x_test).\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Convert predictions from probabilities to actual classes by taking the highest probability\u001b[39;00m\n\u001b[0;32m      8\u001b[0m predicted_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# np.argmax selects the highest value in each prediction (represents the\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#9.Showing some results (The results are predicted according to the number in the pictures based on the test, determining which results obtained a higher value, displaying the results)\n",
    "\n",
    "# Display some results using test data\n",
    "# Make predictions using the test data\n",
    "predictions = model.predict(x_test) # The model generates predictions for all images in the test set (x_test).\n",
    "\n",
    "# Convert predictions from probabilities to actual classes by taking the highest probability\n",
    "predicted_classes = np.argmax(predictions, axis=1) # np.argmax selects the highest value in each prediction (represents the\n",
    "\n",
    "# Convert true labels (which were in one-hot format) to actual numbers\n",
    "true_classes = np.argmax(y_test, axis=1)# Convert true labels from one-hot format to actual numbers (0, 1, 2, ..., 9).\n",
    "\n",
    "# Plot some images with predictions\n",
    "for i in range(10):# Show 10 images from the test data.\n",
    "    plt.imshow(x_test[i].reshape(28, 28), cmap='gray')# Display the image in the correct format (28x28) using grayscale.\n",
    "    plt.title(f'True: {true_classes[i]}, Predicted: {predicted_classes[i]}') # Show the title with the true and predicted number.\n",
    "    plt.axis('off')# Turn off the axes for a clearer image.\n",
    "    plt.show()  # Show the image with the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ckf6YdlUbNVT",
    "outputId": "c45030ca-d111-4e2c-c34b-35a3bf199aad"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#10. Inserting a new image  (We tested the model by inserting external images and verifying the quality of the model’s work)  to predict\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m image \u001b[38;5;66;03m# Importing a library to load images.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# 1. Load a new image from the path\u001b[39;00m\n\u001b[0;32m      6\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/MNIST-2.webp\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Specify the actual path of the image you want to input\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "#10. Inserting a new image  (We tested the model by inserting external images and verifying the quality of the model’s work)  to predict\n",
    "\n",
    "from keras.preprocessing import image # Importing a library to load images.\n",
    "\n",
    "# 1. Load a new image from the path\n",
    "img_path = '/content/drive/MyDrive/MNIST-2.webp'  # Specify the actual path of the image you want to input\n",
    "img = image.load_img(img_path, target_size=(28, 28), color_mode='grayscale')\n",
    "\n",
    "# 2. Convert the image to an array of pixels\n",
    "img_array = image.img_to_array(img)\n",
    "\n",
    "# 3. Normalize the image in the same way as the MNIST data\n",
    "img_array = img_array.astype('float32') / 255.0\n",
    "\n",
    "# 4. Reshape the image to fit the expected input of the neural network (28x28x1)\n",
    "img_array = img_array.reshape(1, 28, 28, 1)\n",
    "\n",
    "# 5. Predict using the trained model\n",
    "prediction = model.predict(img_array)\n",
    "\n",
    "# 6. Display the prediction (the predicted class)\n",
    "predicted_class = np.argmax(prediction, axis=1)\n",
    "print(f'Predicted Class for the input image: {predicted_class[0]}')\n",
    "\n",
    "# Display the input image with the prediction\n",
    "plt.imshow(img_array.reshape(28, 28), cmap='gray')\n",
    "plt.title(f'Predicted Class: {predicted_class[0]}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFL6qp6pbNVT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
